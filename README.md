# Transformer-based Question-Answering Model

This project implements a Transformer-based neural network using TensorFlow to train a question-answering model. The model is trained on a custom dataset of simple question-answer pairs in Ukrainian. It uses a standard transformer architecture with multi-head attention and a feed-forward network to generate responses based on user input.

![Chat with model](https://raw.githubusercontent.com/techn0man1ac/SimpleGPT/refs/heads/main/img/Screenshot.png)

## Key Features:
- Text preprocessing with tokenization and padding
- Multi-layer Transformer model with self-attention
- Sequence generation using a dense output layer
- Custom training loop with loss and accuracy tracking
- Interactive command-line interface for real-time question answering

## Technologies Used:
- TensorFlow
- NumPy
- Python

